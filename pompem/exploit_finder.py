import asyncio

from aiohttp.client_exceptions import ClientConnectorError
from rich import box, print
from rich.console import Console
from rich.table import Table

from .scrapers import CXSecurity, PacketStorm, ZeroDay


class ExploitFinder:
    scrapers = [PacketStorm(), CXSecurity(), ZeroDay()]

    def __init__(self, options):
        self.options = options
        self.output_tables = []
        self.console = Console()

    async def run(self):
        await self.run_scrapers()
        self.show()

    async def run_scrapers(self):
        for tasks in self.make_scrapers_tasks():
            for task in tasks:
                try:
                    await task
                except ClientConnectorError:
                    print(f"[italic red] Problem with scraper: {task.get_name()}")

    def make_scrapers_tasks(self):
        keywords = self.options.keywords.split(",")

        for keyword in keywords:
            yield (
                asyncio.create_task(scraper(keyword), name=type(scraper).__name__)
                for scraper in self.scrapers
            )

    def show(self):
        for scraper in self.scrapers:
            for keyword, exploits in scraper.items():
                table = self.make_table(keyword, exploits, scraper.base_url)
                self.output_tables.append(table)

        for table in self.output_tables:
            self.console.print(table)

    def make_table(self, keyword, exploits, base_url):
        table = Table(title=f"{keyword} exploits, site:{base_url}", box=box.ASCII_DOUBLE_HEAD)
        table.add_column("Date", justify="right", style="green", no_wrap=True)
        table.add_column("Description", style="green")
        table.add_column("Url", style="green")

        for exploit in exploits:
            table.add_row(
                exploit["date"], exploit["name"][:40], f"[link={exploit['url']}]{exploit['url']}[/link]"
            )

        return table
